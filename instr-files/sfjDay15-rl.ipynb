{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement learning - Example\n",
    "### Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "R = np.matrix( [ [-1, -1, -1, -1, 0, -1 ],\n",
    "                 [-1, -1, -1, 0, -1, 100 ],\n",
    "                 [-1, -1, -1, 0, -1, -1 ],\n",
    "                 [-1, 0, 0, -1, 0, -1 ],\n",
    "                 [0, -1, -1, 0, -1, 100 ],\n",
    "                 [-1, 0, -1, -1, 0, 100 ], \n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ -1,  -1,  -1,  -1,   0,  -1],\n",
       "        [ -1,  -1,  -1,   0,  -1, 100],\n",
       "        [ -1,  -1,  -1,   0,  -1,  -1],\n",
       "        [ -1,   0,   0,  -1,   0,  -1],\n",
       "        [  0,  -1,  -1,   0,  -1, 100],\n",
       "        [ -1,   0,  -1,  -1,   0, 100]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q = np.zeros((6,6))\n",
    "Q = np.matrix(np.zeros([6,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state):\n",
    "    current_state_row = R[state]\n",
    "    return np.where(current_state_row >= 0)[1]\n",
    "\n",
    "def next_action(available_actions):\n",
    "    return(int(np.random.choice(available_actions,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_actions(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_action = available_actions(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = next_action(available_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula\n",
    "# Q(state, action) = R(state, action) + 0.8 * Max[Q(next_state, all_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_matrix(current_state, action):\n",
    "    max_index = np.where(Q[action] == np.max(Q[action]))[1]\n",
    "    if max_index.shape[0] > 1:\n",
    "        max_index = int(np.random.choice(max_index, size=1))\n",
    "    else:\n",
    "        max_index = int(max_index)\n",
    "    max_value = Q[action, max_index]\n",
    "    Q[current_state, action] = R[current_state, action] + 0.8 * max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_q_matrix(initial_state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "    available_action = available_actions(current_state)\n",
    "    action = next_action(available_action)\n",
    "    update_q_matrix(current_state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  0.,   0.,   0.,   0., 400.,   0.],\n",
       "        [  0.,   0.,   0., 320.,   0., 500.],\n",
       "        [  0.,   0.,   0., 320.,   0.,   0.],\n",
       "        [  0., 400., 256.,   0., 400.,   0.],\n",
       "        [320.,   0.,   0., 320.,   0., 500.],\n",
       "        [  0., 400.,   0.,   0., 400., 500.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  0. ,   0. ,   0. ,   0. ,  80. ,   0. ],\n",
       "        [  0. ,   0. ,   0. ,  64. ,   0. , 100. ],\n",
       "        [  0. ,   0. ,   0. ,  64. ,   0. ,   0. ],\n",
       "        [  0. ,  80. ,  51.2,   0. ,  80. ,   0. ],\n",
       "        [ 64. ,   0. ,   0. ,  64. ,   0. , 100. ],\n",
       "        [  0. ,  80. ,   0. ,   0. ,  80. , 100. ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize trained Q matrix\n",
    "(Q / np.max(Q)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best policy returned:  [3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model. Goal state=5\n",
    "goal_state = 5\n",
    "current_state = 2 # place an agent in any room\n",
    "steps = []\n",
    "while current_state != goal_state:\n",
    "    next_step_index = np.where(Q[current_state] == np.max(Q[current_state]))[1]\n",
    "    if next_step_index.shape[0] > 1:\n",
    "        next_step_index = int(np.random.choice(next_step_index, size=1))\n",
    "    else:\n",
    "        next_step_index = int(next_step_index)\n",
    "    steps.append(next_step_index)\n",
    "    current_state = next_step_index\n",
    "print('Best policy returned: ', steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gym\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = 2\n",
    "    next_state, reward, done, err = env.step(action)\n",
    "    #env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the formula to calculate Q values\n",
    "# Q(State, Action) = R(State, Action) + Gamma * Max[Q(next state, all actions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Q-table\n",
    "DESCRETE_OBSERVATION_SPACE_SIZE = [20] * len(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DESCRETE_OBSERVATION_SPACE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "descrete_os_win_size = (env.observation_space.high - env.observation_space.low) / DESCRETE_OBSERVATION_SPACE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09 , 0.007])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrete_os_win_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Q-table\n",
    "# Actions --> 0, 1, 2\n",
    "import numpy as np\n",
    "q_table = np.random.uniform(low=-1, high=0, size=(DESCRETE_OBSERVATION_SPACE_SIZE + [env.action_space.n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "streets = gym.make(\"Taxi-v3\").env\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = streets.encode(2,3,2,0)\n",
    "streets.s = initial_state\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.6\n",
    "exploration = 0.1\n",
    "\n",
    "for taxi_run in range(10000):\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        random_val = random.uniform(0,1)\n",
    "        if (random_val < exploration):\n",
    "            action = streets.action_space.sample() #explore a random  action\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # use action with highest q-value\n",
    "        \n",
    "        next_state, reward, done, info = streets.step(action)\n",
    "        \n",
    "        prev_q = q_table[state, action]\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        new_q = (1-learning_rate) * prev_q + learning_rate * (reward + discount_factor*next_max_q)\n",
    "        q_table[state, action] = new_q\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number: 5\n",
      "+---------+\n",
      "|\u001b[43mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "for tripnum in range(1,11):\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state])\n",
    "        next_state, reward, done, info = streets.step(action)\n",
    "        clear_output(wait=True)\n",
    "        print('Trip number: ' + str(tripnum))\n",
    "        print(streets.render(mode='ansi'))\n",
    "        sleep(0.5)\n",
    "        state = next_state\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
